# utils/file_io.py
import os
import json
import re
import piexif
from datetime import datetime, timedelta
import random
import requests
import pytz

# --- C√ÅC H√ÄM ƒê·ªåC/GHI FILE V√Ä CONFIG ---

def load_config(config_path): # <--- Nh·∫≠n v√†o config_path
    """T·∫£i file config.json."""
    try:
        # S·ª¨A L·ªñI: D√πng ƒë√∫ng tham s·ªë config_path ƒë√£ ƒë∆∞·ª£c truy·ªÅn v√†o
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp c·∫•u h√¨nh t·∫°i '{config_path}'!")
        return {}
    except json.JSONDecodeError:
        print(f"L·ªói: File '{config_path}' kh√¥ng ph·∫£i l√† file JSON h·ª£p l·ªá.")
        return {}

def update_total_image_count(filepath, new_counts, tool_name):
    """
    ƒê·ªçc, c·ªông d·ªìn v√† ghi l·∫°i file TotalImage.txt v·ªõi key chi ti·∫øt theo tool.
    """
    totals = {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                if ':' in line:
                    key, count = line.strip().split(':', 1)
                    totals[key.strip()] = int(count.strip())
    except FileNotFoundError:
        print(f"Kh√¥ng t√¨m th·∫•y file {os.path.basename(filepath)}, s·∫Ω t·∫°o file m·ªõi.")
    
    if not new_counts:
        print(f"Kh√¥ng c√≥ ·∫£nh m·ªõi n√†o ƒë∆∞·ª£c t·∫°o ƒë·ªÉ c·∫≠p nh·∫≠t {os.path.basename(filepath)}.")
        return

    # T·∫°o key k·∫øt h·ª£p: tool_name.mockup_name
    for mockup, count in new_counts.items():
        combined_key = f"{tool_name}.{mockup}"
        totals[combined_key] = totals.get(combined_key, 0) + count
        
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            # S·∫Øp x·∫øp theo key ƒë·ªÉ file lu√¥n g·ªçn g√†ng
            for key in sorted(totals.keys()):
                f.write(f"{key}: {totals[key]}\n")
        print(f"üìä ƒê√£ c·∫≠p nh·∫≠t t·ªïng s·ªë ·∫£nh chi ti·∫øt trong {os.path.basename(filepath)}")
    except Exception as e:
        print(f"L·ªói khi ghi file {os.path.basename(filepath)}: {e}")


# --- C√ÅC H√ÄM X·ª¨ L√ù METADATA V√Ä TEXT ---
def pre_clean_filename(base_filename, regex_pattern):
    """
    Ti·ªÅn x·ª≠ l√Ω t√™n file b·∫±ng m·ªôt bi·ªÉu th·ª©c ch√≠nh quy (regex)
    ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong config.
    """
    if not regex_pattern:
        return base_filename
    try:
        return re.sub(regex_pattern, '', base_filename)
    except re.error as e:
        print(f"  - ‚ö†Ô∏è C·∫£nh b√°o: L·ªói bi·ªÉu th·ª©c ch√≠nh quy trong pre_clean_regex: {e}")
        return base_filename


def clean_title(title, keywords):
    """
    D·ªçn d·∫πp ti√™u ƒë·ªÅ file d·ª±a tr√™n keywords, x·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ t√™n file
    d√πng g·∫°ch ngang (-) v√† g·∫°ch d∆∞·ªõi (_).
    """
    # B∆Ø·ªöC 1: Chu·∫©n h√≥a chu·ªói ƒë·∫ßu v√†o -> thay th·∫ø c·∫£ '_' v√† '-' b·∫±ng d·∫•u c√°ch
    normalized_title = title.replace('_', ' ').replace('-', ' ')
    
    # B∆Ø·ªöC 2: X√¢y d·ª±ng pattern ƒë·ªÉ t√¨m v√† x√≥a keywords (logic n√†y v·∫´n hi·ªáu qu·∫£)
    # N√≥ s·∫Ω t√¨m c√°c keywords nh∆∞ "t shirt", "t-shirt"...
    cleaned_keywords = sorted([r'(?:-|\s)?'.join([re.escape(p) for p in re.split(r'[- ]', k.strip())]) for k in keywords], key=len, reverse=True)
    pattern = r'\b(' + '|'.join(cleaned_keywords) + r')\b'

    # B∆Ø·ªöC 3: X√≥a c√°c keywords tr√™n chu·ªói ƒê√É ƒê∆Ø·ª¢C CHU·∫®N H√ìA
    cleaned_str = re.sub(pattern, '', normalized_title, flags=re.IGNORECASE)
    
    # B∆Ø·ªöC 4: D·ªçn d·∫πp c√°c d·∫•u c√°ch th·ª´a v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ cu·ªëi c√πng
    final_title = re.sub(r'\s+', ' ', cleaned_str).strip()
    
    return final_title

def should_globally_skip(filename, skip_keywords):
    """Ki·ªÉm tra filename c√≥ ch·ª©a t·ª´ kh√≥a skip to√†n c·ª•c kh√¥ng."""
    for keyword in skip_keywords:
        if re.search(r'\b' + re.escape(keyword) + r'\b', filename, re.IGNORECASE):
            print(f"Skipping (Global): '{filename}' ch·ª©a t·ª´ kh√≥a b·ªã c·∫•m '{keyword}'.")
            return True
    return False

def _convert_to_gps(value, is_longitude):
    abs_value = abs(value)
    ref = ('E' if value >= 0 else 'W') if is_longitude else ('N' if value >= 0 else 'S')
    degrees = int(abs_value)
    minutes_float = (abs_value - degrees) * 60
    minutes = int(minutes_float)
    seconds_float = (minutes_float - minutes) * 60
    return {
        'value': ((degrees, 1), (minutes, 1), (int(seconds_float * 100), 100)),
        'ref': ref.encode('ascii')
    }

def create_exif_data(prefix, final_filename, exif_defaults):
    domain_exif = prefix + ".com"
    digitized_time = datetime.now() - timedelta(hours=2)
    original_time = digitized_time - timedelta(seconds=random.randint(3600, 7500))
    digitized_str = digitized_time.strftime("%Y:%m:%d %H:%M:%S")
    original_str = original_time.strftime("%Y:%m:%d %H:%M:%S")
    try:
        zeroth_ifd = {
            piexif.ImageIFD.Artist: domain_exif.encode('utf-8'),
            piexif.ImageIFD.Copyright: domain_exif.encode('utf-8'),
            piexif.ImageIFD.ImageDescription: final_filename.encode('utf-8'),
            piexif.ImageIFD.Software: exif_defaults.get("Software", "Adobe Photoshop 25.0").encode('utf-8'),
            piexif.ImageIFD.DateTime: digitized_str.encode('utf-8'),
            piexif.ImageIFD.Make: exif_defaults.get("Make", "").encode('utf-8'),
            piexif.ImageIFD.Model: exif_defaults.get("Model", "").encode('utf-8'),
            piexif.ImageIFD.XPAuthor: domain_exif.encode('utf-16le'),
            piexif.ImageIFD.XPComment: final_filename.encode('utf-16le'),
            piexif.ImageIFD.XPSubject: final_filename.encode('utf-16le'),
            piexif.ImageIFD.XPKeywords: (prefix + ";" + "shirt;").encode('utf-16le')
        }
        exif_ifd = {
            piexif.ExifIFD.DateTimeOriginal: original_str.encode('utf-8'),
            piexif.ExifIFD.DateTimeDigitized: digitized_str.encode('utf-8'),
            piexif.ExifIFD.FNumber: tuple(exif_defaults.get("FNumber", [0,1])),
            piexif.ExifIFD.ExposureTime: tuple(exif_defaults.get("ExposureTime", [0,1])),
            piexif.ExifIFD.ISOSpeedRatings: exif_defaults.get("ISOSpeedRatings", 0),
            piexif.ExifIFD.FocalLength: tuple(exif_defaults.get("FocalLength", [0,1]))
        }
        gps_ifd = {}
        lat, lon = exif_defaults.get("GPSLatitude"), exif_defaults.get("GPSLongitude")
        if lat is not None and lon is not None:
            gps_lat_data, gps_lon_data = _convert_to_gps(lat, False), _convert_to_gps(lon, True)
            gps_ifd.update({
                piexif.GPSIFD.GPSLatitude: gps_lat_data['value'], piexif.GPSIFD.GPSLatitudeRef: gps_lat_data['ref'],
                piexif.GPSIFD.GPSLongitude: gps_lon_data['value'], piexif.GPSIFD.GPSLongitudeRef: gps_lon_data['ref']
            })
        return piexif.dump({"0th": zeroth_ifd, "Exif": exif_ifd, "GPS": gps_ifd})
    except Exception as e:
        print(f"L·ªói khi t·∫°o d·ªØ li·ªáu EXIF: {e}")
        return b''

def find_mockup_image(mockup_dir, mockup_name, color):
    """
    T√¨m file ·∫£nh mockup trong th∆∞ m·ª•c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh.
    H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng .jpg, .webp, .png.
    """
    for ext in ['.jpg', '.webp', '.png']:
        filepath = os.path.join(mockup_dir, f"{mockup_name}_{color}{ext}")
        if os.path.exists(filepath):
            return filepath
    return None

# Th√™m h√†m m·ªõi n√†y v√†o cu·ªëi file
def send_telegram_summary(tool_name, total_image_file_path, session_counts):
    """
    T·∫°o b√°o c√°o chi ti·∫øt, ph√¢n nh√≥m theo tool v√† g·ª≠i qua Telegram.
    B√°o c√°o s·∫Ω bao g·ªìm c·∫£ c√°c mockup kh√¥ng c√≥ ·∫£nh m·ªõi (added: 0).
    """
    print(f"‚úàÔ∏è  Chu·∫©n b·ªã g·ª≠i b√°o c√°o Telegram cho tool: {tool_name}...")
    
    token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")

    if not token or not chat_id:
        print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng Telegram. B·ªè qua."); return

    # 1. T·∫°o ti√™u ƒë·ªÅ v√† timestamp
    header = f"--- Summary of Last {tool_name} Run ---"
    timestamp = datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime('%Y-%m-%d %H:%M:%S %z')
    
    report_body = ""
    try:
        # --- LOGIC M·ªöI ƒê·ªÇ T·∫†O B√ÅO C√ÅO ƒê·∫¶Y ƒê·ª¶ ---

        # 2. ƒê·ªçc t·∫•t c·∫£ d·ªØ li·ªáu t·ªïng t·ª´ file
        all_totals = {}
        with open(total_image_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if ':' in line:
                    key, count = line.strip().split(':', 1)
                    all_totals[key.strip()] = int(count.strip())

        # 3. L·∫•y t·∫•t c·∫£ c√°c mockup li√™n quan ƒë·∫øn tool n√†y (c·∫£ c≈© v√† m·ªõi)
        # L·∫•y t·ª´ l·ªãch s·ª≠
        historical_mockups = {key.split('.', 1)[1] for key in all_totals if key.startswith(f"{tool_name}.")}
        # L·∫•y t·ª´ l·∫ßn ch·∫°y hi·ªán t·∫°i
        session_mockups = set(session_counts.keys())
        # G·ªôp l·∫°i v√† s·∫Øp x·∫øp
        all_relevant_mockups = sorted(list(historical_mockups.union(session_mockups)))

        # 4. T·∫°o b√°o c√°o chi ti·∫øt
        report_lines = []
        if not all_relevant_mockups:
            report_body = "Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c x·ª≠ l√Ω cho tool n√†y."
        else:
            for mockup in all_relevant_mockups:
                # L·∫•y s·ªë m·ªõi th√™m, n·∫øu kh√¥ng c√≥ th√¨ m·∫∑c ƒë·ªãnh l√† 0
                new_count = session_counts.get(mockup, 0)
                
                # L·∫•y t·ªïng s·ªë t·ª´ file
                combined_key = f"{tool_name}.{mockup}"
                total_count = all_totals.get(combined_key, 0)
                
                report_lines.append(f"    {mockup}: {total_count} (added: {new_count})")
            report_body = "\n".join(report_lines)

    except FileNotFoundError:
        report_body = "File TotalImage.txt ch∆∞a ƒë∆∞·ª£c t·∫°o."
    except Exception as e:
        report_body = f"L·ªói khi ƒë·ªçc file b√°o c√°o: {e}"

    # 5. Gh√©p v√† g·ª≠i tin nh·∫Øn (kh√¥ng ƒë·ªïi)
    message = f"{header}\nTimestamp: {timestamp}\n\n{tool_name}:\n{report_body}"

    try:
        requests.post(f"https://api.telegram.org/bot{token}/sendMessage", data={'chat_id': chat_id, 'text': message}, timeout=10)
        print("‚úÖ G·ª≠i b√°o c√°o t·ªõi Telegram th√†nh c√¥ng.")
    except Exception as e:
        print(f"‚ùå L·ªói khi g·ª≠i b√°o c√°o t·ªõi Telegram: {e}")